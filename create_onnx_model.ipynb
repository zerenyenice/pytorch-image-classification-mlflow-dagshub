{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc8c8ab-c2ee-4523-9937-b9391fe8e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83075484-88d7-4676-a266-114c83bbec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.get_model('vit_b_32', weights=None, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0a3c48-0be9-47b9-a4c8-2803f0c1f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('test_2/model_138.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6b1cec-db5f-42f4-9d0d-30d7eb5b14c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5e94f-f949-459d-96eb-aacaacaba4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c2773c3-dd0c-424c-90e8-cc31c7eb820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/chooch/lib/python3.10/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/home/ubuntu/anaconda3/envs/chooch/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:142: FutureWarning: 'onnxscript.values.OnnxFunction.opname' is deprecated in version 0.1 and will be removed in 0.3. Please use '.name' instead.\n",
      "  symbolic_name = f\"{onnx_fn.opset.domain}::{onnx_fn.opname}\"\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 12 WARNING 0 ERROR =======================\n",
      "12 WARNING were not printed due to the log level.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnxscript\n",
    "from onnxscript.onnx_opset import opset18 as op\n",
    "\n",
    "custom_opset = onnxscript.values.Opset(domain=\"torch.onnx\", version=18)\n",
    "\n",
    "@onnxscript.script(custom_opset)\n",
    "def ScaledDotProductAttention(\n",
    "    query,\n",
    "    key,\n",
    "    value,\n",
    "    dropout_p,\n",
    "):\n",
    "    # Swap the last two axes of key\n",
    "    key_shape = op.Shape(key)\n",
    "    key_last_dim = key_shape[-1:]\n",
    "    key_second_last_dim = key_shape[-2:-1]\n",
    "    key_first_dims = key_shape[:-2]\n",
    "    # Contract the dimensions that are not the last two so we can transpose\n",
    "    # with a static permutation.\n",
    "    key_squeezed_shape = op.Concat(\n",
    "        op.Constant(value_ints=[-1]), key_second_last_dim, key_last_dim, axis=0\n",
    "    )\n",
    "    key_squeezed = op.Reshape(key, key_squeezed_shape)\n",
    "    key_squeezed_transposed = op.Transpose(key_squeezed, perm=[0, 2, 1])\n",
    "    key_transposed_shape = op.Concat(key_first_dims, key_last_dim, key_second_last_dim, axis=0)\n",
    "    key_transposed = op.Reshape(key_squeezed_transposed, key_transposed_shape)\n",
    "\n",
    "    embedding_size = op.CastLike(op.Shape(query)[-1], query)\n",
    "    scale = op.Div(1.0, op.Sqrt(embedding_size))\n",
    "\n",
    "    # Scale q, k before matmul for stability see https://tinyurl.com/sudb9s96 for math\n",
    "    query_scaled = op.Mul(query, op.Sqrt(scale))\n",
    "    key_transposed_scaled = op.Mul(key_transposed, op.Sqrt(scale))\n",
    "    attn_weight = op.Softmax(\n",
    "        op.MatMul(query_scaled, key_transposed_scaled),\n",
    "        axis=-1,\n",
    "    )\n",
    "    attn_weight, _ = op.Dropout(attn_weight, dropout_p)\n",
    "    return op.MatMul(attn_weight, value)\n",
    "\n",
    "\n",
    "def custom_scaled_dot_product_attention(g, query, key, value, attn_mask, dropout, is_causal, scale=None):\n",
    "    return g.onnxscript_op(ScaledDotProductAttention, query, key, value, dropout).setType(query.type())\n",
    "\n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::scaled_dot_product_attention\",\n",
    "    symbolic_fn=custom_scaled_dot_product_attention,\n",
    "    opset_version=18,\n",
    ")\n",
    "\n",
    "@onnxscript.script(custom_opset)\n",
    "def aten_unflatten(self, dim, sizes):\n",
    "    \"\"\"unflatten(Tensor(a) self, int dim, SymInt[] sizes) -> Tensor(a)\"\"\"\n",
    "\n",
    "    self_size = op.Shape(self)\n",
    "\n",
    "    if dim < 0:\n",
    "        # PyTorch accepts negative dim as reversed counting\n",
    "        self_rank = op.Size(self_size)\n",
    "        dim = self_rank + dim\n",
    "\n",
    "    head_start_idx = op.Constant(value_ints=[0])\n",
    "    head_end_idx = op.Reshape(dim, op.Constant(value_ints=[1]))\n",
    "    head_part_rank = op.Slice(self_size, head_start_idx, head_end_idx)\n",
    "\n",
    "    tail_start_idx = op.Reshape(dim + 1, op.Constant(value_ints=[1]))\n",
    "    #tail_end_idx = op.Constant(value_ints=[_INT64_MAX])\n",
    "    tail_end_idx = op.Constant(value_ints=[9223372036854775807]) # = sys.maxint, exactly 2^63 - 1 -> 64 bit int\n",
    "    tail_part_rank = op.Slice(self_size, tail_start_idx, tail_end_idx)\n",
    "\n",
    "    final_shape = op.Concat(head_part_rank, sizes, tail_part_rank, axis=0)\n",
    "\n",
    "    return op.Reshape(self, final_shape)\n",
    "\n",
    "def custom_unflatten(g, *dim, **shape):\n",
    "    return g.onnxscript_op(aten_unflatten, *dim, **shape)    \n",
    "    \n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::unflatten\",\n",
    "    symbolic_fn=custom_unflatten,\n",
    "    opset_version=18,\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cpu')\n",
    "\n",
    "input_names = [\"image\"]\n",
    "output_names = [\"class\"]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model_onnx_test_81.onnx\", export_params=True, verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names, opset_version=18, custom_opsets = {\"torch.onnx\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55505089-0e0f-4bda-83ee-d3a1fe47120d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1acca85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963ef30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.get_model('vit_b_32', weights=None, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d851143",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('test_2/model_138.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0a2579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715bf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89370650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/chooch/lib/python3.10/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/home/ubuntu/anaconda3/envs/chooch/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:142: FutureWarning: 'onnxscript.values.OnnxFunction.opname' is deprecated in version 0.1 and will be removed in 0.3. Please use '.name' instead.\n",
      "  symbolic_name = f\"{onnx_fn.opset.domain}::{onnx_fn.opname}\"\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of torch.onnx::aten_unflatten type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 12 WARNING 0 ERROR =======================\n",
      "12 WARNING were not printed due to the log level.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnxscript\n",
    "from onnxscript.onnx_opset import opset18 as op\n",
    "\n",
    "custom_opset = onnxscript.values.Opset(domain=\"torch.onnx\", version=18)\n",
    "\n",
    "@onnxscript.script(custom_opset)\n",
    "def ScaledDotProductAttention(\n",
    "    query,\n",
    "    key,\n",
    "    value,\n",
    "    dropout_p,\n",
    "):\n",
    "    # Swap the last two axes of key\n",
    "    key_shape = op.Shape(key)\n",
    "    key_last_dim = key_shape[-1:]\n",
    "    key_second_last_dim = key_shape[-2:-1]\n",
    "    key_first_dims = key_shape[:-2]\n",
    "    # Contract the dimensions that are not the last two so we can transpose\n",
    "    # with a static permutation.\n",
    "    key_squeezed_shape = op.Concat(\n",
    "        op.Constant(value_ints=[-1]), key_second_last_dim, key_last_dim, axis=0\n",
    "    )\n",
    "    key_squeezed = op.Reshape(key, key_squeezed_shape)\n",
    "    key_squeezed_transposed = op.Transpose(key_squeezed, perm=[0, 2, 1])\n",
    "    key_transposed_shape = op.Concat(key_first_dims, key_last_dim, key_second_last_dim, axis=0)\n",
    "    key_transposed = op.Reshape(key_squeezed_transposed, key_transposed_shape)\n",
    "\n",
    "    embedding_size = op.CastLike(op.Shape(query)[-1], query)\n",
    "    scale = op.Div(1.0, op.Sqrt(embedding_size))\n",
    "\n",
    "    # Scale q, k before matmul for stability see https://tinyurl.com/sudb9s96 for math\n",
    "    query_scaled = op.Mul(query, op.Sqrt(scale))\n",
    "    key_transposed_scaled = op.Mul(key_transposed, op.Sqrt(scale))\n",
    "    attn_weight = op.Softmax(\n",
    "        op.MatMul(query_scaled, key_transposed_scaled),\n",
    "        axis=-1,\n",
    "    )\n",
    "    attn_weight, _ = op.Dropout(attn_weight, dropout_p)\n",
    "    return op.MatMul(attn_weight, value)\n",
    "\n",
    "\n",
    "def custom_scaled_dot_product_attention(g, query, key, value, attn_mask, dropout, is_causal, scale=None):\n",
    "    return g.onnxscript_op(ScaledDotProductAttention, query, key, value, dropout).setType(query.type())\n",
    "\n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::scaled_dot_product_attention\",\n",
    "    symbolic_fn=custom_scaled_dot_product_attention,\n",
    "    opset_version=18,\n",
    ")\n",
    "\n",
    "@onnxscript.script(custom_opset)\n",
    "def aten_unflatten(self, dim, sizes):\n",
    "    \"\"\"unflatten(Tensor(a) self, int dim, SymInt[] sizes) -> Tensor(a)\"\"\"\n",
    "\n",
    "    self_size = op.Shape(self)\n",
    "\n",
    "    if dim < 0:\n",
    "        # PyTorch accepts negative dim as reversed counting\n",
    "        self_rank = op.Size(self_size)\n",
    "        dim = self_rank + dim\n",
    "\n",
    "    head_start_idx = op.Constant(value_ints=[0])\n",
    "    head_end_idx = op.Reshape(dim, op.Constant(value_ints=[1]))\n",
    "    head_part_rank = op.Slice(self_size, head_start_idx, head_end_idx)\n",
    "\n",
    "    tail_start_idx = op.Reshape(dim + 1, op.Constant(value_ints=[1]))\n",
    "    #tail_end_idx = op.Constant(value_ints=[_INT64_MAX])\n",
    "    tail_end_idx = op.Constant(value_ints=[9223372036854775807]) # = sys.maxint, exactly 2^63 - 1 -> 64 bit int\n",
    "    tail_part_rank = op.Slice(self_size, tail_start_idx, tail_end_idx)\n",
    "\n",
    "    final_shape = op.Concat(head_part_rank, sizes, tail_part_rank, axis=0)\n",
    "\n",
    "    return op.Reshape(self, final_shape)\n",
    "\n",
    "def custom_unflatten(g, *dim, **shape):\n",
    "    return g.onnxscript_op(aten_unflatten, *dim, **shape)    \n",
    "    \n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::unflatten\",\n",
    "    symbolic_fn=custom_unflatten,\n",
    "    opset_version=18,\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cpu')\n",
    "\n",
    "input_names = [\"image\"]\n",
    "output_names = [\"class\"]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model_onnx_test_81.onnx\", export_params=True, verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names, opset_version=18, custom_opsets = {\"torch.onnx\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ac248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chooch",
   "language": "python",
   "name": "chooch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
